<h1> House Prices - Advanced Regression Techniques </h1>
Predict sales prices and practice feature engineering, RFs, and gradient boosting <br>
from: https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/overview


<h2> Competition Description:</h2>
Ask a home buyer to describe their dream house, and they probably won't begin with the height of the basement ceiling or the proximity to an east-west railroad. But this playground competition's dataset proves that much more influences price negotiations than the number of bedrooms or a white-picket fence.

With 79 explanatory variables describing (almost) every aspect of residential homes in Ames, Iowa, this competition challenges you to predict the final price of each home.

<h2> Conclusions and reflections: </h2>
Random forest regression model was chosen to accomodate both categorical and numerical data, trees=45 was experimentally found to be the optimal number<br>
Kaggle Score: 0.14724<br>
Ranking: top 48% at the time of submission<br><br>

First time participating in Kaggle competitions, wasn't expecting too much, mainly hoping to refresh myslef with everything learnt. Struggle with packages such as numpy and pandas occasionally, shall revisit this problem and compare with the results with different models.
